{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e35587",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install silence_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67efcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.image_dataset import image_dataset_from_directory\n",
    "url = 'E:/CRM/UL/5/foto mono/Cotton plant disease'\n",
    "dataset = image_dataset_from_directory(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714be53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd565e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import image_dataset\n",
    "train_set = image_dataset_from_directory(\n",
    "    url,\n",
    "    validation_split = 0.3,\n",
    "    subset = \"training\",\n",
    "    seed = 123,\n",
    "    image_size = (256, 256),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5aa610",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = image_dataset_from_directory(\n",
    "    url,\n",
    "    validation_split = 0.15,\n",
    "    subset = \"validation\",\n",
    "    seed = 123,\n",
    "    image_size = (256, 256),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bad867",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = image_dataset_from_directory(\n",
    "    url,\n",
    "    validation_split = 0.15,\n",
    "    subset = \"validation\",\n",
    "    seed = 123,\n",
    "    image_size = (256, 256),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melhoria de desempenho config\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_set = test_set.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "val_set = val_set.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "test_set = test_set.cache().prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c78548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando dados\n",
    "data_augumentation = tf.keras.models.Sequential()\n",
    "data_augumentation.add(layers.experimental.preprocessing.RandomFlip('horizontal'))\n",
    "data_augumentation.add(layers.experimental.preprocessing.RandomFlip('vertical'))\n",
    "data_augumentation.add(layers.experimental.preprocessing.RandomRotation(0.2))\n",
    "data_augumentation.add(layers.experimental.preprocessing.RandomZoom(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5998b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "for x, label in test_set:\n",
    "    y.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for i in range(len(y)):\n",
    "  for j in range(len(y[i])):\n",
    "    test_labels.append(y[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91fe5c",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47754d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#objeto de sequencia de camadas\n",
    "CNN = tf.keras.models.Sequential()\n",
    "\n",
    "#Aumento de dados\n",
    "CNN.add(data_augumentation)\n",
    "\n",
    "#normalizando os dados em escala [0;1]\n",
    "CNN.add(layers.Rescaling(1./255))\n",
    "\n",
    "# #adicionando o primeiro bloco de convolucao e max pooling\n",
    "CNN.add(layers.Conv1D(128, 3, activation = 'relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#adicionando o segundo bloco de convolucao e max pooling\n",
    "CNN.add(layers.Conv2D(256, 3, activation = 'relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#adicionando o terceiro bloco de convolucao e max pooling\n",
    "CNN.add(layers.Conv2D(512, 3, activation = 'relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#adicionando o quarto bloco de convolucao e max pooling\n",
    "CNN.add(layers.Conv2D(512, 3, activation = 'relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#adicionando o quarto bloco de convolucao e max pooling\n",
    "CNN.add(layers.Conv2D(1024, 3, activation = 'relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "#adicionando o quarto bloco de convolucao e max pooling\n",
    "CNN.add(layers.Conv2D(1024, 3, activation = 'relu'))\n",
    "CNN.add(layers.MaxPooling2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718eca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando camadas de classificacao\n",
    "CNN.add(layers.Flatten())\n",
    "CNN.add(layers.Dense(1024, activation = 'relu'))\n",
    "CNN.add(layers.Dropout(0.25))\n",
    "CNN.add(layers.Dense(1024, activation = 'relu'))\n",
    "CNN.add(layers.Dropout(0.2))\n",
    "CNN.add(layers.Dense(17, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ponderacao de classes\n",
    "class_weight = {0.1, 0.1, 4, 0.2, 2, 0.2, 0.9, 2, 0.9, 0.7, 0.9, 0.4, 10, 0.4, 10, 0.2, 2}\n",
    "class ClassWeightCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.model.optimizer.class_weights = class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec361298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilacao do modelo\n",
    "CNN.compile(optimizer = 'adam',\n",
    "                      loss = 'sparse_categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', patience= 4, verbose= 1, mode='min', factor=  0.2, min_lr = 1e-6)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 8 , verbose=1, mode='min', restore_best_weights= True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/CNN', monitor='val_loss', verbose=1, save_best_only=True, mode= 'min')\n",
    "\n",
    "callbacks= [reduceLR, early_stopping, checkpoint, ClassWeightCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4626caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.fit(train_set, validation_data = val_set, epochs = 100, callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da accuracia do modelo treinamento e valisacao em relacao as épocas\n",
    "plt.plot(CNN.history.history['accuracy'])\n",
    "plt.plot(CNN.history.history['val_accuracy'])\n",
    "plt.title('Acurácia do modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03937ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da erro do modelo treinamento e valisacao em relacao as épocas\n",
    "plt.plot(CNN.history.history['loss'])\n",
    "plt.plot(CNN.history.history['val_loss'])\n",
    "plt.title('Erro do modelo')\n",
    "plt.ylabel('Erro')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "export_path = \"C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/CNN/{}\".format(int(t))\n",
    "CNN.save(export_path, save_format = 'tf')\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe43932",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f22705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_labels = np.argmax(CNN.predict(test_set), axis=1)\n",
    "\n",
    "print(classification_report(test_labels, predicted_labels, target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcao para plotar matriz de confusao\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(actual, predic):\n",
    "\n",
    "    cm = confusion_matrix(actual, predic)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    cmap=plt.cm.Reds\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Matriz de confusão', fontsize = 20)\n",
    "\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation = 90, fontsize = 12)\n",
    "    plt.yticks(tick_marks, class_names, fontsize = 12)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 14)\n",
    "\n",
    "    plt.ylabel('Classes Verdadeiras', fontsize = 18, color = 'green')\n",
    "    plt.xlabel('Classes preditadas', fontsize = 18, color = 'red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando a matriz de confusao\n",
    "plot_confusion_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "a = accuracy_score(test_labels, predicted_labels)\n",
    "p = precision_score(test_labels, predicted_labels, average = 'macro')\n",
    "r = recall_score(test_labels, predicted_labels, average = 'macro')\n",
    "f = f1_score(test_labels, predicted_labels, average = 'macro')\n",
    "\n",
    "print(\"Acuracia: \", a)\n",
    "print(\"Precisao: \", p)\n",
    "print(\"Recall: \", r)\n",
    "print(\"F1-score: \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo o mdelo CNN\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(CNN)\n",
    "\n",
    "\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Salvando o modelo.\n",
    "with open('C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/CNN/CNNLite.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc9587",
   "metadata": {},
   "source": [
    "# MobileNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a47551",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (256, 256) + (3,)\n",
    "model_MobileNetV2 = tf.keras.applications.MobileNetV2(\n",
    "    input_shape = IMG_SHAPE,\n",
    "    include_top = False,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "model_MobileNetV2.trainable = False\n",
    "\n",
    "model_MobileNetV2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf43041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#objeto de sequencia de camadas MobileNet V2\n",
    "MNet = tf.keras.models.Sequential()\n",
    "\n",
    "#Aumento de dados\n",
    "MNet.add(data_augumentation)\n",
    "\n",
    "#normalizando os dados em escala\n",
    "MNet.add(layers.Rescaling(1./127.5, offset=-1))\n",
    "MNet.add(model_MobileNetV2)\n",
    "MNet.add(layers.GlobalAveragePooling2D())\n",
    "MNet.add(layers.Flatten())\n",
    "MNet.add(layers.Dense(1024, activation = 'relu'))\n",
    "MNet.add(layers.Dense(1024, activation = 'relu'))\n",
    "MNet.add(layers.Dense(17, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilacao do modelo\n",
    "MNet.compile(optimizer = 'adam',\n",
    "                      loss = 'sparse_categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ab120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ponderacao de classes\n",
    "class_weight = {0.1, 0.1, 4, 0.2, 2, 0.2, 0.9, 2, 0.9, 0.7, 0.9, 0.4, 10, 0.4, 10, 0.2, 2}\n",
    "class ClassWeightCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.model.optimizer.class_weights = class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', patience= 4, verbose= 1, mode='min', factor=  0.2, min_lr = 1e-6)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 8 , verbose=1, mode='min', restore_best_weights= True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/CNN', monitor='val_loss', verbose=1, save_best_only=True, mode= 'min')\n",
    "\n",
    "callbacks= [reduceLR, early_stopping, checkpoint, ClassWeightCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91999e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNet.fit(train_set, validation_data = val_set, epochs = 100, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09658b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da accuracia do modelo treinamento e valisacao em relacao as épocas\n",
    "plt.plot(MNet.history.history['accuracy'])\n",
    "plt.plot(MNet.history.history['val_accuracy'])\n",
    "plt.title('Acurácia do modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da erro do modelo treinamento e valisacao em relacao as épocas\n",
    "plt.plot(MNet.history.history['loss'])\n",
    "plt.plot(MNet.history.history['val_loss'])\n",
    "plt.title('Erro do modelo')\n",
    "plt.ylabel('Erro')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "export_path = \"C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/MobileNet/{}\".format(int(t))\n",
    "MNet.save(export_path, save_format = 'tf')\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d780e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44879ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_labels = np.argmax(MNet.predict(test_set), axis=1)\n",
    "\n",
    "print(classification_report(test_labels, predicted_labels, target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6173b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando a matriz de confusao\n",
    "plot_confusion_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "a = accuracy_score(test_labels, predicted_labels)\n",
    "p = precision_score(test_labels, predicted_labels, average = 'macro')\n",
    "r = recall_score(test_labels, predicted_labels, average = 'macro')\n",
    "f = f1_score(test_labels, predicted_labels, average = 'macro')\n",
    "\n",
    "print(\"Acuracia: \", a)\n",
    "print(\"Precisao: \", p)\n",
    "print(\"Recall: \", r)\n",
    "print(\"F1-score: \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fa24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MNet='C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/MobileNet/'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(path_MNet)\n",
    "tflite_model = converter.convert()\n",
    "with open('C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/MNLite.tflite', 'wb') as f: f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f8080",
   "metadata": {},
   "source": [
    "# VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (256, 256) + (3,)\n",
    "model_VGG = tf.keras.applications.VGG16(\n",
    "    input_shape = IMG_SHAPE,\n",
    "    include_top = False,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "model_VGG.trainable = False\n",
    "\n",
    "model_VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#objeto de sequencia de camadas VGG\n",
    "modelVGG = tf.keras.models.Sequential()\n",
    "\n",
    "#Aumento de dados\n",
    "modelVGG.add(data_augumentation)\n",
    "\n",
    "#normalizando os dados em escala\n",
    "modelVGG.add(layers.Rescaling(1./255))\n",
    "modelVGG.add(model_VGG)\n",
    "modelVGG.add(layers.GlobalAveragePooling2D())\n",
    "modelVGG.add(layers.Dense(256, activation = 'relu'))\n",
    "modelVGG.add(layers.Dense(512, activation = 'relu'))\n",
    "modelVGG.add(layers.Dropout(0.2))\n",
    "modelVGG.add(layers.Dense(1024, activation = 'relu'))\n",
    "modelVGG.add(layers.Dense(1024, activation = 'relu'))\n",
    "modelVGG.add(layers.Dense(17, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b864a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0.1, 0.1, 4, 0.2, 2, 0.2, 0.9, 2, 0.9, 0.7, 0.9, 0.4, 10, 0.4, 10, 0.2, 2}\n",
    "class ClassWeightCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.model.optimizer.class_weights = class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fac19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilacao do modelo\n",
    "modelVGG.compile(optimizer = 'adam',\n",
    "                      loss = 'sparse_categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837251c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', patience= 4, verbose= 1, mode='min', factor=  0.2, min_lr = 1e-4)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 8 , verbose=1, mode='min', restore_best_weights= True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/VGG', monitor='val_loss', verbose=1, save_best_only=True, mode= 'min')\n",
    "\n",
    "callbacks= [reduceLR, early_stopping, checkpoint, ClassWeightCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15cff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG.fit(train_set, validation_data = val_set, epochs = 100, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809db564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da accuracia do modelo treinamento e valisacao em relacao as épocas\n",
    "plt.plot(modelVGG.history.history['accuracy'])\n",
    "plt.plot(modelVGG.history.history['val_accuracy'])\n",
    "plt.title('Acurácia do modelo')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da erro do modelo treinamento e valisacao em relacao as épocas\n",
    "plt.plot(modelVGG.history.history['loss'])\n",
    "plt.plot(modelVGG.history.history['val_loss'])\n",
    "plt.title('Erro do modelo')\n",
    "plt.ylabel('Erro')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "export_path = \"C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/VGG/{}\".format(int(t))\n",
    "modelVGG.save(export_path, save_format = 'tf')\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77098a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b249e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_labels = np.argmax(modelVGG.predict(test_set), axis=1)\n",
    "\n",
    "print(classification_report(test_labels, predicted_labels, target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29071601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_confusion_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "a = accuracy_score(test_labels, predicted_labels)\n",
    "p = precision_score(test_labels, predicted_labels, average = 'macro')\n",
    "r = recall_score(test_labels, predicted_labels, average = 'macro')\n",
    "f = f1_score(test_labels, predicted_labels, average = 'macro')\n",
    "\n",
    "print(\"Acuracia: \", a)\n",
    "print(\"Precisao: \", p)\n",
    "print(\"Recall: \", r)\n",
    "print(\"F1-score: \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MNet='C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/VGG/'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(path_MNet)\n",
    "tflite_model = converter.convert()\n",
    "with open('C:/Users/DREY/OneDrive/Documents/Moda/Notebooks/Models/VGGLite.tflite', 'wb') as f: f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
